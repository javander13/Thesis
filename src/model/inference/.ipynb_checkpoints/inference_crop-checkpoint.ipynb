{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Test the trained and saved on model on the cropped Eilat images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom scripts\n",
    "from utils import *\n",
    "import config \n",
    "\n",
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling sources of randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padd images\n",
    "\n",
    "#scene = 'selected'\n",
    "#imagePaths = sorted(list(paths.list_images('/data/jantina/data/CoralNet/inference/images/'+scene+'/')))\n",
    "\n",
    "#for images in imagePaths:\n",
    "    #im = Image.open(images)\n",
    "    #im_new = padd(im, 12, 96, 0, 0, (0, 0, 0)) \n",
    "    #imagePath = '/data/jantina/data/CoralNet/inference/images_padded/'+scene+'/' + images.split(os.path.sep)[-1]\n",
    "    #im_new.save(imagePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: 'no label',\n",
    "           1: 'hard coral',\n",
    "           2: 'hard coral bleached',\n",
    "           3: 'dead coral',\n",
    "           4: 'other invertebrates',\n",
    "           5: 'sand/rubble',\n",
    "           6: 'other',\n",
    "           7: '(macro) algae',\n",
    "           8: 'seagrass',\n",
    "           9: 'unknown'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.colors.ListedColormap(['1',\n",
    "                                  (0.3215686274509804, 0.32941176470588235, 0.6392156862745098),\n",
    "                                  (0.611764705882353, 0.6196078431372549, 0.8705882352941177),\n",
    "                                  (0.8392156862745098, 0.3803921568627451, 0.4196078431372549),\n",
    "                                  (0.5490196078431373, 0.42745098039215684, 0.19215686274509805),\n",
    "                                  (0.9058823529411765, 0.796078431372549, 0.5803921568627451),\n",
    "                                  (0.8705882352941177, 0.6196078431372549, 0.8392156862745098),\n",
    "                                  (0.38823529411764707, 0.4745098039215686, 0.2235294117647059),\n",
    "                                  (0.7098039215686275, 0.8117647058823529, 0.4196078431372549),\n",
    "                                  (0.6470588235294118, 0.3176470588235294, 0.5803921568627451)\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, imagePath, x_min, y_min, x_max, y_max):\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn off gradient tracking\n",
    "    with torch.no_grad():\n",
    "        # load the image from disk\n",
    "        image = io.imread(imagePath)\n",
    "        \n",
    "        # load the labels from disk\n",
    "        groundTruthPath = '/data/jantina/data/CoralNet/inference/labels/'+scene+ imagePath.split(os.path.sep)[-1]+'.tif'\n",
    "        Label = io.imread(groundTruthPath)\n",
    "        \n",
    "        # add padding \n",
    "        gtLabel = np.zeros((512,896))\n",
    "        gtLabel[12:512,:800] = Label\n",
    "        \n",
    "        # define transformation\n",
    "        test_transform = A.Compose([\n",
    "            A.Crop(x_min=x_min, y_min=y_min, x_max=x_max, y_max=y_max),    \n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "    \n",
    "        # apply transformation\n",
    "        transformed = test_transform(image=image, mask=gtLabel)\n",
    "        image = transformed[\"image\"]\n",
    "        gtLabel = transformed[\"mask\"]\n",
    "        \n",
    "        # create image tensor\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.to(\"cuda\")\n",
    "        \n",
    "        # create mask tensor\n",
    "        asarray = lambda x: torch.tensor(np.array(x), dtype=torch.long)\n",
    "        gtLabel = asarray(np.expand_dims(gtLabel, 0))\n",
    "\n",
    "        # prediction\n",
    "        predLabel = model(image).squeeze()\n",
    "        predLabel = torch.argmax(predLabel, dim=0)\n",
    "        predLabel = predLabel.cpu()\n",
    "        \n",
    "    return image, gtLabel.squeeze(), predLabel    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize metrics\n",
    "confmat = ConfusionMatrix(num_classes=10)\n",
    "acc = torchmetrics.Accuracy(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = [0, 128, 256, 384, 512, 640, 768]\n",
    "x_max = [128, 256, 384, 512, 640, 768, 896]\n",
    "y_min = [0, 128, 256, 384]\n",
    "y_max = [128, 256, 384, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = 'scene_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading up test image paths...\n"
     ]
    }
   ],
   "source": [
    "# load the image paths corresponding to the images\n",
    "print(\"[INFO] loading up test image paths...\")\n",
    "directory = '/data/jantina/data/CoralNet/inference/images_padded/'+scene\n",
    "\n",
    "# load our model from disk and flash it to the current device\n",
    "print(\"[INFO] load up model...\")\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/small/output/unet.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/medium/output/unet.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(config.MODEL_PATH).to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output_dense/unet.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output/unet2.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output/weighted.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output/eilat.pth\").to(config.DEVICE)\n",
    "\n",
    "\n",
    "conf = np.zeros((10,10)) \n",
    "totalaccu = 0\n",
    "countacc = 0\n",
    "\n",
    "for path in os.listdir(directory):        \n",
    "    imagePath = os.path.join(directory, path)\n",
    "    for i in range(7):\n",
    "        for j in range(4):\n",
    "            image, gtLabel, predLabel = make_predictions(unet, \n",
    "                                                         imagePath,\n",
    "                                                         x_min[i], \n",
    "                                                         y_min[j], \n",
    "                                                         x_max[i], \n",
    "                                                         y_max[j])\n",
    "            \n",
    "            conf += np.array(confmat(predLabel, gtLabel.squeeze()))\n",
    "\n",
    "            if torch.sum(gtLabel)!=0:\n",
    "                countacc += 1\n",
    "                totalaccu += acc(predLabel, gtLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5169)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalaccu/countacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "           0: 'hard coral',\n",
    "           1: 'dead coral',\n",
    "           2: 'other invertebrates',\n",
    "           3: 'sand/rubble',\n",
    "           4: 'other',\n",
    "           5: '(macro) algae',\n",
    "          }\n",
    "\n",
    "norm = np.copy(conf)\n",
    "\n",
    "for i in range(len(conf)):\n",
    "    if conf.sum(axis=1)[:, np.newaxis][i] != 0:\n",
    "        norm[i,:] = conf[i,:] / conf.sum(axis=1)[:, np.newaxis][i]\n",
    "   \n",
    "\n",
    "norm = norm[1:, 1:]\n",
    "norm = np.delete(norm, 1, 0)\n",
    "norm = np.delete(norm, 1, 1)\n",
    "norm = np.delete(norm, 6, 0)\n",
    "norm = np.delete(norm, 6, 1)\n",
    "norm = np.delete(norm, 6, 0)\n",
    "norm = np.delete(norm, 6, 1)\n",
    "\n",
    "# confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "ax = sns.heatmap(norm, annot=True, cmap='Blues', linewidths=.5, ax=ax, annot_kws={\"size\": 25})\n",
    "\n",
    "#ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Category', fontsize = 25)\n",
    "ax.set_ylabel('Actual Category\\n ', fontsize = 25)\n",
    "\n",
    "cax = plt.gcf().axes[-1]\n",
    "cax.tick_params(labelsize=25)\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(list(classes.values()),rotation = 30, fontsize = 25)\n",
    "ax.yaxis.set_ticklabels(list(classes.values()),rotation = 30, fontsize = 25)\n",
    "\n",
    "plt.savefig('eilat_confmat.pdf')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
