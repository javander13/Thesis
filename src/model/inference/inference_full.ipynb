{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "Test the trained and saved on model on the patched Eilat images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom scripts\n",
    "from utils import *\n",
    "import config \n",
    "\n",
    "# import the necessary packages\n",
    "from imutils import paths\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling sources of randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd(pil_img, top, right, bottom, left, color):\n",
    "    width, height = pil_img.size\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    result = Image.new(pil_img.mode, (new_width, new_height), color)\n",
    "    result.paste(pil_img, (left, top))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padd images\n",
    "\n",
    "#scene = 'selected'\n",
    "#imagePaths = sorted(list(paths.list_images('/data/jantina/data/CoralNet/inference/images/'+scene+'/')))\n",
    "\n",
    "#for images in imagePaths:\n",
    "    #im = Image.open(images)\n",
    "    #im_new = padd(im, 12, 96, 0, 0, (0, 0, 0)) \n",
    "    #imagePath = '/data/jantina/data/CoralNet/inference/images_padded/'+scene+'/' + images.split(os.path.sep)[-1]\n",
    "    #im_new.save(imagePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0: 'no label',\n",
    "           1: 'hard coral',\n",
    "           2: 'hard coral bleached',\n",
    "           3: 'dead coral',\n",
    "           4: 'other invertebrates',\n",
    "           5: 'sand/rubble',\n",
    "           6: 'other',\n",
    "           7: '(macro) algae',\n",
    "           8: 'seagrass',\n",
    "           9: 'unknown'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.colors.ListedColormap(['1',\n",
    "                                  (0.3215686274509804, 0.32941176470588235, 0.6392156862745098),\n",
    "                                  (0.611764705882353, 0.6196078431372549, 0.8705882352941177),\n",
    "                                  (0.8392156862745098, 0.3803921568627451, 0.4196078431372549),\n",
    "                                  (0.5490196078431373, 0.42745098039215684, 0.19215686274509805),\n",
    "                                  (0.9058823529411765, 0.796078431372549, 0.5803921568627451),\n",
    "                                  (0.8705882352941177, 0.6196078431372549, 0.8392156862745098),\n",
    "                                  (0.38823529411764707, 0.4745098039215686, 0.2235294117647059),\n",
    "                                  (0.7098039215686275, 0.8117647058823529, 0.4196078431372549),\n",
    "                                  (0.6470588235294118, 0.3176470588235294, 0.5803921568627451)\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, imagePath, x_min, y_min, x_max, y_max):\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn off gradient tracking\n",
    "    with torch.no_grad():\n",
    "        # load the image from disk\n",
    "        image = io.imread(imagePath)\n",
    "        \n",
    "        # load the labels from disk\n",
    "        groundTruthPath = '/data/jantina/data/CoralNet/inference/labels/'+scene+ imagePath.split(os.path.sep)[-1]+'.tif'\n",
    "        Label = io.imread(groundTruthPath)\n",
    "        \n",
    "        # add padding \n",
    "        gtLabel = np.zeros((512,896))\n",
    "        gtLabel[12:512,:800] = Label\n",
    "        \n",
    "        # define transformation\n",
    "        test_transform = A.Compose([\n",
    "            A.Crop(x_min=x_min, y_min=y_min, x_max=x_max, y_max=y_max),    \n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "    \n",
    "        # apply transformation\n",
    "        transformed = test_transform(image=image, mask=gtLabel)\n",
    "        image = transformed[\"image\"]\n",
    "        gtLabel = transformed[\"mask\"]\n",
    "        \n",
    "        # create image tensor\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = np.expand_dims(image, 0)\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.to(\"cuda\")\n",
    "        \n",
    "        # create mask tensor\n",
    "        asarray = lambda x: torch.tensor(np.array(x), dtype=torch.long)\n",
    "        gtLabel = asarray(np.expand_dims(gtLabel, 0))\n",
    "\n",
    "        # prediction\n",
    "        predLabel = model(image).squeeze()\n",
    "        predLabel = torch.argmax(predLabel, dim=0)\n",
    "        predLabel = predLabel.cpu()\n",
    "        \n",
    "    return predLabel    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, target):    \n",
    "    return np.where(pred-target==0)[0].shape[0]/np.count_nonzero(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = [0, 128, 256, 384, 512, 640, 768]\n",
    "x_max = [128, 256, 384, 512, 640, 768, 896]\n",
    "y_min = [0, 128, 256, 384]\n",
    "y_max = [128, 256, 384, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = 'scene_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image paths corresponding to the images\n",
    "print(\"[INFO] loading up test image paths...\")\n",
    "directory = '/data/jantina/data/CoralNet/inference/images_padded/'+scene\n",
    "\n",
    "# load our model from disk and flash it to the current device\n",
    "print(\"[INFO] load up model...\")\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/small/output/unet.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/medium/output/unet.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(config.MODEL_PATH).to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output_dense/unet.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output/unet2.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output/weighted.pth\").to(config.DEVICE)\n",
    "#unet = torch.load(\"/data/jantina/data/CoralNet/dataset/output/eilat.pth\").to(config.DEVICE)\n",
    "\n",
    "\n",
    "conf = np.zeros((10,10)) \n",
    "totalaccu = 0\n",
    "countacc = 0\n",
    "\n",
    "for path in os.listdir(directory):    \n",
    "    pred = np.zeros((512,896))\n",
    "    \n",
    "    imagePath = os.path.join(directory, path)\n",
    "    \n",
    "    for i in range(7):\n",
    "        for j in range(4):\n",
    "            predLabel = make_predictions(unet, imagePath, x_min[i], y_min[j], x_max[i], y_max[j])\n",
    "            pred[y_min[j]:y_max[j],x_min[i]: x_max[i]] = predLabel.numpy()\n",
    "            \n",
    "    groundTruthPath = '/data/jantina/data/CoralNet/inference/labels/'+scene+ imagePath.split(os.path.sep)[-1]+'.tif'\n",
    "    label = io.imread(groundTruthPath)\n",
    "    \n",
    "    imagePath = '/data/jantina/data/CoralNet/inference/images/'+scene+ imagePath.split(os.path.sep)[-1]\n",
    "    image = io.imread(imagePath)\n",
    "    \n",
    "    pred = pred[12:512,0:800]\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(label,\n",
    "               cmap = cmap,\n",
    "               vmin=0, vmax=9)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(pred, \n",
    "               cmap = cmap,\n",
    "               vmin=0, vmax=9)\n",
    "    \n",
    "    # add colour bar\n",
    "    cbar = plt.colorbar(ticks=list(classes.keys()), fraction=0.045)\n",
    "    cbar.ax.set_yticklabels(list(classes.values()))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    if np.sum(label)!=0:\n",
    "        print(\"[INFO] Accuracy \", accuracy(pred, label))\n",
    "        totalaccu = totalaccu+accuracy(pred, label)\n",
    "        countacc +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6547275271303048"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalaccu/countacc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
