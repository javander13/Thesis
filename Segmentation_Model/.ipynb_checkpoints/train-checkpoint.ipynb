{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from dataset import Dataset\n",
    "from model import UNet\n",
    "import config \n",
    "\n",
    "from torch.nn import CrossEntropyLoss \n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving testing image paths...\n"
     ]
    }
   ],
   "source": [
    "# load the image and mask filepaths in a sorted manner\n",
    "imagePaths = sorted(list(paths.list_images(config.IMAGE_DATASET_PATH)))\n",
    "maskPaths = sorted(list(paths.list_images(config.MASK_DATASET_PATH)))\n",
    "\n",
    "# partition the data into training and testing splits using 85% of\n",
    "# the data for training and the remaining 15% for testing\n",
    "split = train_test_split(imagePaths, maskPaths, test_size=config.TEST_SPLIT, random_state=42)\n",
    "\n",
    "# unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainMasks, testMasks) = split[2:]\n",
    "\n",
    "# write the testing image paths to disk so that we can use then\n",
    "# when evaluating/testing our model\n",
    "print(\"[INFO] saving testing image paths...\")\n",
    "f = open(config.TEST_PATHS, \"w\")\n",
    "f.write(\"\\n\".join(testImages))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 1079 examples in the training set...\n",
      "[INFO] found 191 examples in the test set...\n"
     ]
    }
   ],
   "source": [
    "# create the train and test datasets\n",
    "trainDS = Dataset(imagePaths=trainImages, maskPaths=trainMasks)\n",
    "testDS = Dataset(imagePaths=testImages, maskPaths=testMasks)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
    "\n",
    "# create the training and test data loaders\n",
    "trainLoader = DataLoader(trainDS, shuffle=True, \n",
    "                         batch_size=config.BATCH_SIZE, \n",
    "                         pin_memory=config.PIN_MEMORY, \n",
    "                         num_workers=os.cpu_count())\n",
    "\n",
    "testLoader = DataLoader(testDS, shuffle=False, \n",
    "                        batch_size=config.BATCH_SIZE, \n",
    "                        pin_memory=config.PIN_MEMORY, \n",
    "                        num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our UNet model\n",
    "unet = UNet().to(config.DEVICE)\n",
    "\n",
    "# initialize loss function and optimizer\n",
    "lossFunc = CrossEntropyLoss()\n",
    "opt = Adam(unet.parameters(), lr=config.INIT_LR)\n",
    "\n",
    "# calculate steps per epoch for training and test set\n",
    "trainSteps = len(trainDS) // config.BATCH_SIZE\n",
    "testSteps = len(testDS) // config.BATCH_SIZE\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"test_loss\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                            | 1/40 [00:45<29:22, 45.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 1/40\n",
      "Train loss: 5.923221, Test loss: 8.3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███                                                           | 2/40 [01:30<28:38, 45.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 2/40\n",
      "Train loss: 5.852283, Test loss: 8.1644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▋                                                         | 3/40 [02:15<27:50, 45.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 3/40\n",
      "Train loss: 5.460791, Test loss: 6.6120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████▏                                                       | 4/40 [03:00<27:01, 45.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 4/40\n",
      "Train loss: 4.086093, Test loss: 5.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▊                                                      | 5/40 [03:45<26:13, 44.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 5/40\n",
      "Train loss: 3.555172, Test loss: 4.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████████▎                                                    | 6/40 [04:31<25:47, 45.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 6/40\n",
      "Train loss: 3.271532, Test loss: 4.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████▊                                                   | 7/40 [05:17<25:09, 45.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 7/40\n",
      "Train loss: 2.979704, Test loss: 4.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████▍                                                 | 8/40 [06:03<24:19, 45.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EPOCH: 8/40\n",
      "Train loss: 2.917495, Test loss: 4.0339\n"
     ]
    }
   ],
   "source": [
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(config.NUM_EPOCHS)):\n",
    "    # set the model in training mode\n",
    "    unet.train()\n",
    "\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalTestLoss = 0\n",
    "    \n",
    "    # loop over the training set\n",
    "    for (i, (x, y)) in enumerate(trainLoader):\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "        \n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = unet(x)\n",
    "        loss = lossFunc(pred, y)\n",
    "        \n",
    "        # first, zero out any previously accumulated gradients, then\n",
    "        # perform backpropagation, and then update model parameters\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # add the loss to the total training loss so far\n",
    "        totalTrainLoss += loss.item()\n",
    "    \n",
    "    # switch off autograd\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        unet.eval()\n",
    "        \n",
    "        # loop over the validation set\n",
    "        for (x, y) in testLoader:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "            \n",
    "            \n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = unet(x)\n",
    "            totalTestLoss += lossFunc(pred, y).item()\n",
    "            \n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgTestLoss = totalTestLoss / testSteps\n",
    "    \n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss)\n",
    "    H[\"test_loss\"].append(avgTestLoss)\n",
    "    \n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, config.NUM_EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(avgTrainLoss, avgTestLoss))\n",
    "    \n",
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
    "plt.title(\"Training Loss on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(config.PLOT_PATH)\n",
    "\n",
    "# serialize the model to disk\n",
    "torch.save(unet, config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
