{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper for CoralNet\n",
    "\n",
    "This scraper allows the download of a full dataset on CoralNet.\n",
    "\n",
    "Datasets can also be filled with new images when more are confirmed.\n",
    "\n",
    "For each source dowload:\n",
    "- `labelset.csv`\n",
    "- `metadata.csv`\n",
    "- `annotations.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare directory for data download\n",
    "\n",
    "In the `/data/jantina` drive the sources are organised as such:\n",
    "```\n",
    "CoralNet\n",
    "│ \n",
    "└─── WAPA_RFM\n",
    "│   │\n",
    "│   └─── images\n",
    "│   │      \n",
    "│   └─── labels\n",
    "│   │      \n",
    "│   └─── masks    \n",
    "│   │      \n",
    "│   └─── output      \n",
    "│   │      \n",
    "│   └─── other   \n",
    "│\n",
    "└─── other\n",
    "    │     \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of images:  47\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/data/jantina/CoralNet\")\n",
    "\n",
    "# create the data folder\n",
    "path = \"Aukane_Reef\"\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "    print(\"[INFO] The new directory is created!\")\n",
    "    \n",
    "# create an image folder\n",
    "os.chdir(path)\n",
    "isExist = os.path.exists(\"images\")\n",
    "if not isExist:\n",
    "    os.makedirs(\"images\")\n",
    "    print(\"[INFO] The new image folder is created!\")\n",
    "\n",
    "# read image metadata\n",
    "df = pd.read_csv('other/metadata.csv')\n",
    "imageList = df['Name']\n",
    "print('[INFO] Number of images: ', imageList.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get image names and links from specific source\n",
    "\n",
    "Parse the CoralNet source code using BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 47 images to download.\n"
     ]
    }
   ],
   "source": [
    "# declare variables\n",
    "searchList = imageList\n",
    "names = []\n",
    "links = []\n",
    "\n",
    "# grab the link from the specific source\n",
    "page_url = \"https://coralnet.ucsd.edu/source/2720/browse/images/\"\n",
    "\n",
    "# grab image names and links\n",
    "for i in range(1,4):\n",
    "    # grab the source code\n",
    "    r = requests.post(page_url,\n",
    "                 data = {\"csrfmiddlewaretoken\": \"JXuaXzWXyLNJBNruOX685IdY0L7iL1gn6m5SQyWKN3JHbBk1zIdZ32tw4B1Jlluk\",\n",
    "                         #\"image_form_type\": \"search\",\n",
    "                         #\"photo_date_1\": 2020,\n",
    "                         #\"annotation_status\": \"confirmed\",\n",
    "                         #\"last_annotated_1\": 2020,\n",
    "                         #\"sort_method\": \"name\",\n",
    "                         #\"sort_direction\": \"asc\",\n",
    "                         \"page\": i},\n",
    "                 headers={'Referer': page_url,\n",
    "                          \"Cookie\": \"__utmc=209852167; __utmz=209852167.1651666647.1.1.utmcsr=google|utmccn=(organic)|utmcmd=organic|utmctr=(not%20provided); csrftoken=S2NTHiiDHomFqLglSikWZwmQkIFLUkHtfroBAhiqWGiD0z9SD3rNXQCooyzcuEVq; sessionid=vyo2ksxe1ig372r6hbv1lr5ws68egxv2; __utma=209852167.1649723512.1651666647.1651666647.1651736260.2; __utmt=1; __utmb=209852167.5.10.1651736260\"})\n",
    "    \n",
    "    # parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    # extract names\n",
    "    for image in soup.find_all(\"img\"):\n",
    "        name = image[\"title\"].split(\" - Confirmed\")[0]\n",
    "        names.append(name)\n",
    "        \n",
    "        # for source with nasty names\n",
    "        #if name.find(\":\")!=-1:\n",
    "            #continue\n",
    "        #else:\n",
    "            #name = name.split(\"/\")[0] + \".jpeg\"\n",
    "    \n",
    "    # extract links\n",
    "    for link in soup.find_all('a'):\n",
    "        if \"/image/\" in link.get('href'):\n",
    "            img_url = 'https://coralnet.ucsd.edu' + link.get('href')\n",
    "            r = requests.get(img_url)\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            div = soup.find(id = \"original_image_container\")\n",
    "            link = div.find('img').attrs['src']\n",
    "            links.append(link)        \n",
    "            \n",
    "print((f'[INFO] Found {len(links)} images to download.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in only missing images\n",
    "\n",
    "If the source is new, skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "directory = os.chdir(\"/data/jantina/CoralNet/WAPA_RFM/images_almost_all/\")\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    filenames.append(filename)\n",
    "\n",
    "searchList = (list(set(searchList) - set(filenames)))\n",
    "print((f'[INFO] Found {len(searchList)} images to download.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dowload all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded image 10A.png\n",
      "downloaded image 10B.png\n",
      "downloaded image 10C.png\n",
      "downloaded image 10D.png\n",
      "downloaded image 11A11A.png\n",
      "downloaded image 11B11B.png\n",
      "downloaded image 11C11C.png\n",
      "downloaded image 11D11D.png\n",
      "downloaded image 12A12A.png\n",
      "downloaded image 12B.png\n",
      "downloaded image 12C12C.png\n",
      "downloaded image 12D.png\n",
      "downloaded image 1AScreen Shot 2021-08-06 at 3.02.07 pm.png\n",
      "downloaded image 1B1B.png\n",
      "downloaded image 1C1C.png\n",
      "downloaded image 1D1D.png\n",
      "downloaded image 2A2A.png\n",
      "downloaded image 2B2B.png\n",
      "downloaded image 2C2C.png\n",
      "downloaded image 2D2D.png\n",
      "downloaded image 3A3A.png\n",
      "downloaded image 3B.png\n",
      "downloaded image 3C.png\n",
      "downloaded image 3D.png\n",
      "downloaded image 4A4A.png\n",
      "downloaded image 4B4B.png\n",
      "downloaded image 4C.png\n",
      "downloaded image 4D4D.png\n",
      "downloaded image 5A.png\n",
      "downloaded image 5B.png\n",
      "downloaded image 5C.png\n",
      "downloaded image 5D.png\n",
      "downloaded image 6A6A.png\n",
      "downloaded image 6B6B.png\n",
      "downloaded image 6C6C.png\n",
      "downloaded image 6D6D.png\n",
      "downloaded image 7A7A.png\n",
      "downloaded image 7B7B.png\n",
      "downloaded image 7D7D.png\n",
      "downloaded image 8A8A.png\n",
      "downloaded image 8B8B.png\n",
      "downloaded image 8C8C.png\n",
      "downloaded image 8D8D.png\n",
      "downloaded image 9A.png\n",
      "downloaded image 9B.png\n",
      "downloaded image 9C.png\n",
      "downloaded image 9D.png\n",
      "[INFO] Found 47 images.\n"
     ]
    }
   ],
   "source": [
    "# go to the image folder\n",
    "os.chdir(\"/data/jantina/CoralNet/Aukane_Reef/images/\")\n",
    "\n",
    "k = 0\n",
    "for i in range(len(names)):\n",
    "    # cross reference the names with the searchList\n",
    "    if names[i] in set(names) & set(searchList):\n",
    "        # get the image from the URL\n",
    "        r = requests.get(links[i], allow_redirects=True)\n",
    "\n",
    "        # write it to a local file\n",
    "        try:\n",
    "            open(names[i], 'wb').write(r.content)\n",
    "            # increment the number of images we have found\n",
    "            k = k + 1\n",
    "            print(\"downloaded image \" + names[i])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "print(f'[INFO] Found {k} images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
